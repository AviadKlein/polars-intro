{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "930de69e",
   "metadata": {},
   "source": [
    "<img src=\"https://www.pola.rs/share.jpg\" width=400 height=200></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8475e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install polars altair great-tables colorzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0444c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfdb056",
   "metadata": {},
   "source": [
    "# On the history of `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05507dad",
   "metadata": {},
   "source": [
    "<img src=\"./df_hist.png\" width=1000 height=500></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09287a1a",
   "metadata": {},
   "source": [
    "# Why the name \"Polars\"?\n",
    "\n",
    "<font size=5>Because Pandas started it!</font>\n",
    "\n",
    "<font size=5>Pandas: **Pan**el **Da**ta</font>\n",
    "\n",
    "<font size=5>Polars: still an ursine, but with the `rs` suffix</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7586d15a",
   "metadata": {},
   "source": [
    "# Who?\n",
    "\n",
    "https://www.ritchievink.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e3bae8",
   "metadata": {},
   "source": [
    "# Why?\n",
    "\n",
    "### 1. Based on the Rust programming language, which is a very interesting language to know, might be very relevant for DS one day. polars has a python and a rust api.\n",
    "### 2. FAST!\n",
    "### 3. Can operate on datasets beyond the RAM size\n",
    "### 4. Come for speed, stay for the API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bba9dd",
   "metadata": {},
   "source": [
    "# A few words on Rust \n",
    "\n",
    "1. C/C++ performance \n",
    "2. Memory safety\n",
    "3. Out of the box parallelism and concurrency\n",
    "4. Data processing and ML: \n",
    "    - [Linfa](https://github.com/rust-ml/linfa) - scikit equivalent\n",
    "    - [Burn](https://github.com/tracel-ai/burn) - DL package\n",
    "    - [Polars](https://github.com/pola-rs/polars) - pandas equivalent\n",
    "    \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Rust_programming_language_black_logo.svg/2048px-Rust_programming_language_black_logo.svg.png\" width=50 height=50></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40606fce",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9fa3ec",
   "metadata": {},
   "source": [
    "## What we will cover:\n",
    "\n",
    "- Benefits of polars, namely speed\n",
    "- API differences from Pandas\n",
    "- Eager API\n",
    "- Lazy API\n",
    "- SQL API (Yes, you can use polars directly with SQL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f4f8a4",
   "metadata": {},
   "source": [
    "# The main claim to fame: _speed_\n",
    "\n",
    "[Link1](https://duckdblabs.github.io/db-benchmark/), [Link2](https://pola.rs/posts/benchmarks/)\n",
    "\n",
    "## `polars` uses apache's Arrow internally which allows for optimized columnar storage\n",
    "\n",
    "- `numpy`/`pandas` $\\rightarrow$ `polars`: slow since a lot of conversion takes place...\n",
    "- python primitives $\\rightarrow$ `polars`: very fast\n",
    "- binary files, parquet files... $\\rightarrow$ `polars`: smart and fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be79f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = pl.Series([_ for _ in range(50_000_000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeaa931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fails on 100M, while polars achieves it in ~6.2 seconds\n",
    "%time _ = pd.Series([_ for _ in range(50_000_000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b730f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.choice(['A', 'B', 'C'], size=100_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda89684",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pls = pl.Series(arr) # very slow due to conversion from numpy, better to work with primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17842b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pds = pd.Series(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab58c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pls.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d31389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pds.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957accb9",
   "metadata": {},
   "source": [
    "## How long does it take to load a 5M row data set in Polars vs. Pandas? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58799ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file_location = './limited-memory-example/yellow_tripdata_2015-01.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12e51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df_5m = pl.read_csv(_file_location, n_rows=5_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pd_df = pd.read_csv(_file_location, nrows=5_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0110188",
   "metadata": {},
   "source": [
    "#### The full dataset contains 12,748,986 rows and 19 columns\n",
    "\n",
    "#### Reading the full dataset with pandas will kill the kernel...\n",
    "\n",
    "#### On polars, however..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754db9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df = pl.read_csv(_file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f574892a",
   "metadata": {},
   "source": [
    "#### Forcing it to use the arrow parser is even shorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df = pl.read_csv(_file_location, use_pyarrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffde76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebe76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1ef736",
   "metadata": {},
   "source": [
    "## polars DataFrames have `Schema`s\n",
    "\n",
    "[`Schemas`](https://docs.pola.rs/api/python/dev/reference/dataframe/api/polars.DataFrame.schema.html) operate like `dict` with keys that are the column names and types that are part of `polars` magic.\n",
    "\n",
    "Some key methods are:\n",
    "- `names()` can also be accessed via `df.columns`\n",
    "- `dtypes()`\n",
    "- `values()`\n",
    "- `items()`\n",
    "- `keys()`\n",
    "- `to_python()`- will return a `dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386718c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns # is equivalent to df.schema.names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.estimated_size('gb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81252c8b",
   "metadata": {},
   "source": [
    "## Dtypes\n",
    "\n",
    "### `polars` uses columnar storage, since logically, every column has 1 type, having a declared type for each column allows for storing and treating each column separately and in an optimized way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96114e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema['VendorID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56970a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = df.schema['VendorID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04dcd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(type(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190172c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.min(), dt.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88cb431",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.is_numeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.is_decimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e01c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.is_(df.schema['passenger_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb7038",
   "metadata": {},
   "source": [
    "### dtypes can help us optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416eeca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['store_and_fwd_flag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "_c = df['store_and_fwd_flag'].cast(pl.Categorical()) # special data type for low cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea1460",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df['store_and_fwd_flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f07eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _c.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e139f101",
   "metadata": {},
   "source": [
    "# Eager Execution using `polars`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3606c0e0",
   "metadata": {},
   "source": [
    "## Basic DataFrame methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8922d3",
   "metadata": {},
   "source": [
    "### Creating DataFrames ad hoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1835b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.DataFrame({'a': [1,2,3,4], 'b': [4,5,6,7]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our NYC dataset\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Note that strings are quoted \"some str\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5619b29",
   "metadata": {},
   "source": [
    "## Some attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a8246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.height  # how many rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48479402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.width  # how many columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c016052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.flags  # holds the information if a column is sorted or not to avoid repeat sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ed929f",
   "metadata": {},
   "source": [
    "### The `describe()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994fda95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df_5m.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pd_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f478767",
   "metadata": {},
   "source": [
    "## Indexing: No `index` attribute, no `loc`/`iloc` methods... \n",
    "instead one canjust refer to row number (0 based indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20d416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c323d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VendorID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a75e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0,'VendorID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1000:1004,['tpep_dropoff_datetime', 'pickup_longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd3e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf2d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc3edae",
   "metadata": {},
   "source": [
    "## A common `pandas` pattern is to use masks for filtering...\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('/somewhere/something.csv')\n",
    "\n",
    "mask = df['age'] > 30\n",
    "\n",
    "df = df[mask] # would filter the DataFrame\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786000a1",
   "metadata": {},
   "source": [
    "## ... but it's not supported in `polars` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ab196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['VendorID'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b41c3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[mask, 'passenger_count'] # this should fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488bb7e",
   "metadata": {},
   "source": [
    "## ... we'll get to `filter` later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a077b17",
   "metadata": {},
   "source": [
    "## Other indexing methods `rows`/`iter_rows`/`rows_by_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1538f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex = pl.DataFrame(\n",
    "     {\n",
    "         \"x\": [\"a\", \"b\", \"b\", \"a\"],\n",
    "         \"y\": [1, 2, 3, 4],\n",
    "         \"z\": [0, 3, 6, 9],\n",
    "     }\n",
    ")\n",
    "\n",
    "df_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c387663b",
   "metadata": {},
   "source": [
    "### <font color='red'>Materialization Warning:</font> Use with caution: `rows`\n",
    "\n",
    "Unlike `pandas`, `polars` does not store the values of the dataframe directly in memory, there is some disk usage that takes place and also the serialization is columnar, so when we call `rows()` it means that:<br>\n",
    "1 - we materialize the entire dataframe<br>\n",
    "2 - we circulate through each row and each column resulting in $O(N\\times C)$ complexity<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56103d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex.rows() # a very expensive operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7776cab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex.rows(named=True) # or use df_ex.to_dicts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1996b12f",
   "metadata": {},
   "source": [
    "### Memory effective option is using iterators: `iter_rows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414d64d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df_ex.iter_rows():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27721dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "_sum = 0\n",
    "for row in df_ex.iter_rows():\n",
    "    _sum += row[1]\n",
    "    \n",
    "print(f\"the sum of the 2nd column is {_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2592e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value of last column in each row as a list\n",
    "[row[-1] for row in df_ex.iter_rows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783694f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value of named in each row as a list\n",
    "[row['x'] for row in df_ex.iter_rows(named=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045af5c4",
   "metadata": {},
   "source": [
    "### <font color='red'>Materialization Warning:</font> `rows_by_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13486b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fbf2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex.rows_by_key(key=['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex.rows_by_key(key=['x'], named=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9afccd4",
   "metadata": {},
   "source": [
    "###  Unsure? Confused? You can always go back `to_pandas` or `to_numpy` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9911d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73ed98b",
   "metadata": {},
   "source": [
    "## Expressions\n",
    "\n",
    "### (The diagram is my own)\n",
    "\n",
    "<img src=\"./api_layers.png\" height=1200 width=400></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0566947",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = pl.col(\"VendorID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8473126",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c277fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2481dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(c1).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e4b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.col(\"VendorID\", \"pickup_longitude\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"VendorID\", \"pickup_longitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235ea62d",
   "metadata": {},
   "source": [
    "### Filtering using expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a652cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pl.col(\"pickup_longitude\") > -73."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfec01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask # Not materialized, just the instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749cde8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28624d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type((pl.col(\"pickup_longitude\") > -73.) & (pl.col(\"passenger_count\") < 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b0409",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\n",
    "    (pl.col(\"pickup_longitude\") > -73.) &\n",
    "    (pl.col(\"passenger_count\") < 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7d8202",
   "metadata": {},
   "source": [
    "### Adding columns - the wrong way (another common `pandas` pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x'] = 1 # this should fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d654667",
   "metadata": {},
   "source": [
    "### Adding columns - the right way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147282a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(pl.Series('x', [1]*df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e71b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('x').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708915a9",
   "metadata": {},
   "source": [
    "### Using literals: a safer way to work with constants as expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9af6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_lit = pl.lit(1)\n",
    "_lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af0b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(_lit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(pl.lit(2).alias('y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022124a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('y', 'x', 'VendorID').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b668f7",
   "metadata": {},
   "source": [
    "### Using expressions to add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b9a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex.select(pl.col('x'), pl.col('y')+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77caa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ex.select( \n",
    "    \n",
    "    (pl.col('y')/2).alias('y/2'),\n",
    "    \n",
    "    (2/pl.col('y')).alias('2/y'),\n",
    "    \n",
    "    (pl.col('y') + pl.col('z')).alias('y+z'),\n",
    "    \n",
    "    pl.col('z').arctan().alias('arctan(z)'),\n",
    "    \n",
    "    pl.col('z').arctan().ceil().alias('ceil(arctan(z))'),\n",
    "    \n",
    "    (pl.col('z')-5).abs().alias('abs(z-5)'),\n",
    "    \n",
    "    pl.col('z').is_in([1,2,3]).alias('z is in (1,2,3)'),\n",
    "    \n",
    "    pl.col('z').pow(2).alias('z**2'),\n",
    "    \n",
    "    (pl.col('y')**2).alias('y**2')\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148683a3",
   "metadata": {},
   "source": [
    "### Casting types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a1471",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.col('VendorID').cast(pl.String))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11074a75",
   "metadata": {},
   "source": [
    "### But I really like my python function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01243747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plus_2(x):\n",
    "    return x+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8157992",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    original=pl.col('VendorID'), \n",
    "    plus_2=pl.col('VendorID').pipe(plus_2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bbee9d",
   "metadata": {},
   "source": [
    "### Case when.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e538747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a month_name column\n",
    "df = df.with_columns(\n",
    "    (pl.col(\"tpep_pickup_datetime\").dt.strftime(\"%b\").alias(\"month_name\")),\n",
    "    (pl.col(\"tpep_pickup_datetime\").dt.strftime(\"%d\").alias(\"month_day\").cast(pl.Int64)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51866a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('tpep_pickup_datetime', 'month_name', 'month_day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b25e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_col = (\n",
    "    pl.when(pl.col('month_day') <= 10)\n",
    "      .then(pl.lit('first 10 days'))\n",
    "      .when(pl.col('month_day') <= 20)\n",
    "      .then(pl.lit('middle 10 days'))\n",
    "      .otherwise(pl.lit('last 10 days'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5817d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(my_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbd3386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(my_col.alias('day_group'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad9f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('tpep_pickup_datetime', 'day_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd8d38",
   "metadata": {},
   "source": [
    "### Removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb324036",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('x') # or an iterator or a pointer to a pl.col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384450d3",
   "metadata": {},
   "source": [
    "## Group by\n",
    "\n",
    "<font color='red'>A note on api method names:</font> words will always be separated by an underscore `group_by`, `value_counts` etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4521743",
   "metadata": {},
   "source": [
    "### agg expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a2b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.col('passenger_count').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7415b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pl.col('passenger_count').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by('month_name', 'day_group').agg(\n",
    "    pl.len().alias('trips'), # count(1) like SQL\n",
    "    pl.col('passenger_count').sum().alias('passengers'),\n",
    "    pl.col('trip_distance').sum().alias('distance_driven'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fce895",
   "metadata": {},
   "source": [
    "### `group_by_dynamic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f4f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (\n",
    "    df.filter(pl.col('month_day') <= 3)\n",
    "        .sort('tpep_pickup_datetime')\n",
    "        .group_by_dynamic('tpep_pickup_datetime', every='1h')\n",
    "        .agg(\n",
    "            pl.len().alias('trips'),\n",
    "            pl.col('passenger_count').sum().alias('passengers'),\n",
    "            pl.col('trip_distance').sum().alias('distance_driven')\n",
    "        )\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(result['tpep_pickup_datetime'], result['trips'])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c3b7e",
   "metadata": {},
   "source": [
    "<font color='red'>Note:</font>`polars` supports built-in plotting methods like `pandas`, but not using matplotlib. It uses `altair` instead, which works on `pandas` natively, not sure why this package was chosen for integration..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot.line(x='tpep_pickup_datetime', y='trips').properties(\n",
    "    width=600,\n",
    "    height=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc12513",
   "metadata": {},
   "source": [
    "### SQL-like analytic functions are also available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75947c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = {\n",
    "    'partition_by': [None],\n",
    "    'order_by': ['tpep_pickup_datetime']\n",
    "}\n",
    "\n",
    "result = (\n",
    "    df.filter(pl.col('month_day') == 1)\n",
    "        .sort('tpep_pickup_datetime')\n",
    "        .group_by_dynamic('tpep_pickup_datetime', every='1h')\n",
    "        .agg(pl.len().alias('trips'))\n",
    "        .with_columns(pl.col('trips').cum_sum()\n",
    "                      .over(**window)\n",
    "                      .alias('cumulative_trips'))\n",
    "        .with_columns((pl.col('cumulative_trips') / pl.col('trips').sum().over([None])).alias('F'))\n",
    "        .rename({'tpep_pickup_datetime':'hour'})\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a037002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(8,3))\n",
    "ax.plot(result['hour'], result['F'])\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a54700",
   "metadata": {},
   "source": [
    "### Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4aa6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = (\n",
    "    df.filter(pl.col('month_day') == 1)\n",
    "        .sort('tpep_pickup_datetime')\n",
    "        .group_by_dynamic('tpep_pickup_datetime', every='1h')\n",
    "        .agg(pl.len().alias('trips'))\n",
    "        .with_columns(pl.col('tpep_pickup_datetime').dt.strftime('%H').alias('hour'))\n",
    ")\n",
    "\n",
    "result2 = (\n",
    "    df.filter(pl.col('month_day') == 2)\n",
    "        .sort('tpep_pickup_datetime')\n",
    "        .group_by_dynamic('tpep_pickup_datetime', every='1h')\n",
    "        .agg(pl.len().alias('trips'))\n",
    "        .with_columns(pl.col('tpep_pickup_datetime').dt.strftime('%H').alias('hour'))\n",
    ")\n",
    "\n",
    "result1.join(result2, on='hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca21bb5",
   "metadata": {},
   "source": [
    "# Lazy API\n",
    "\n",
    "So far we've been showing the 'eager' api, that performs calculations 'as they come'.\n",
    "\n",
    "The **lazy** api works in a 'tell me what you want to do, and let me do it on my own' fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db4eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = pl.scan_csv(_file_location)\n",
    "lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90029c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04368b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lf.explain())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa79e630",
   "metadata": {},
   "source": [
    "### What the hell is $\\pi */19$?\n",
    "\n",
    "It's part of **relational algebra** (the math behind SQL), and it means:\n",
    "- $\\pi$ is the projection operator (in this case it just means 'select')\n",
    "- ... the set of all rows * \n",
    "- ... over 19 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d98a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = (\n",
    "    pl.scan_csv(_file_location)\n",
    "    .with_columns(pl.col('tpep_pickup_datetime').str.strptime(pl.Datetime, format=\"%Y-%m-%d %H:%M:%S\"))\n",
    "    .filter(pl.col('VendorID') == 1)\n",
    "    .sort('tpep_pickup_datetime')\n",
    "    .group_by_dynamic('tpep_pickup_datetime', every='1h')\n",
    "    .agg(\n",
    "        pl.len().alias('trips'),\n",
    "        pl.col('passenger_count').sum().alias('passengers'),\n",
    "        pl.col('trip_distance').sum().alias('distance_driven')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cad838",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf.show_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aafcc2",
   "metadata": {},
   "source": [
    "The $\\sigma$ operator is another of operation in Relational Algebra that is related to filters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80de7618",
   "metadata": {},
   "source": [
    "### What can we know about the LazyFrame without materializing it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020559b0",
   "metadata": {},
   "source": [
    "#### <font color='red'>Materialization Warning:</font> calling `columns` will perform materialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec582a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should warn with PerformanceWarning\n",
    "%time lf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b451562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# better to use 'collect_schema'\n",
    "%time lf.collect_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9cd492",
   "metadata": {},
   "source": [
    "### But there's no data here, just instructions. So using indices for example, will result in an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6adb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf[0:1,'trips'] # this should fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0313ea",
   "metadata": {},
   "source": [
    "### Materialization has to be explicit, using `collect` to get a `polars.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2eba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time lazy_result = lf.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c2327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eager_time_test():\n",
    "    return (\n",
    "        pl.read_csv(_file_location)\n",
    "        .with_columns(pl.col('tpep_pickup_datetime').str.strptime(pl.Datetime, format=\"%Y-%m-%d %H:%M:%S\"))\n",
    "        .filter(pl.col('VendorID') == 1)\n",
    "        .sort('tpep_pickup_datetime')\n",
    "        .group_by_dynamic('tpep_pickup_datetime', every='1h')\n",
    "        .agg(\n",
    "            pl.len().alias('trips'),\n",
    "            pl.col('passenger_count').sum().alias('passengers'),\n",
    "            pl.col('trip_distance').sum().alias('distance_driven')\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time eager_result = eager_time_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time lazy_result = lf.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "eager_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_result.equals(eager_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2bea26",
   "metadata": {},
   "source": [
    "### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b593a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, profile_result = lf.profile(show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efb5217",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7330fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, profile_result = lf.profile(show_plot=True, predicate_pushdown=False, projection_pushdown=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0ff452",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954e46ee",
   "metadata": {},
   "source": [
    "### Directly creating LazyDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac3c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.DataFrame({'a': [1,2,3]}).lazy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae7674b",
   "metadata": {},
   "source": [
    "## SQL API (Lazy by definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa942a",
   "metadata": {},
   "source": [
    "<img src=\"./sql_api.png\" width=\"400\" height=\"400\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f980d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = (\n",
    "    df.filter(pl.col('month_day') == 1)\n",
    "        .sort('tpep_pickup_datetime')\n",
    "        .group_by_dynamic('tpep_pickup_datetime', every='1h')\n",
    "        .agg(\n",
    "            pl.len().alias('trips'),\n",
    "            pl.col('passenger_count').sum().alias('passengers'),\n",
    "            pl.col('trip_distance').sum().alias('distance_driven')\n",
    "        )\n",
    "    .with_columns(pl.col('tpep_pickup_datetime').dt.strftime('%H').alias('hour'))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3549f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f27302",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.sql(\"\"\"select avg(distance_driven) as avg_distance from result1\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02777d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.sql(\"\"\"select avg(distance_driven) as avg_distance from result1\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867ae9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = (\n",
    "    df.filter(pl.col('month_day') == 3) # <-- 2nd day\n",
    "        .sort('tpep_pickup_datetime')\n",
    "        .group_by_dynamic('tpep_pickup_datetime', every='1h')\n",
    "        .agg(\n",
    "            pl.len().alias('trips'),\n",
    "            pl.col('passenger_count').sum().alias('passengers'),\n",
    "            pl.col('trip_distance').sum().alias('distance_driven')\n",
    "        )\n",
    "    .with_columns(pl.col('tpep_pickup_datetime').dt.strftime('%H').alias('hour'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8c9372",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pl.sql(\"\"\"\n",
    "    select \n",
    "        t1.hour, \n",
    "        t1.distance_driven as dist1, \n",
    "        t2.distance_driven as dist2\n",
    "    from result1 as t1 join result2 as t2 on t1.hour = t2.hour\n",
    "    order by 1\n",
    "\"\"\")\n",
    "\n",
    "mat = result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e777397",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9264783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(mat['hour'], mat['dist1'], label='day 1')\n",
    "plt.plot(mat['hour'], mat['dist2'], label='day 2')\n",
    "plt.legend()\n",
    "plt.yscale('symlog')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a5131f",
   "metadata": {},
   "source": [
    "## If you don't want to run the entire computation, just to check if you did things correctly\n",
    "\n",
    "### Use `head(n).collect()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head(2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ada8638",
   "metadata": {},
   "source": [
    "## The SQL API also supports `pandas` DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb43c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = pd.DataFrame({'key':[1,2,3], 'a':[0,0,1]})\n",
    "pl_df = pl.DataFrame({'key':[1,2,3], 'b':[1,0,0]})\n",
    "\n",
    "pl.sql(\"\"\"\n",
    "    select\n",
    "        pd_df.key,\n",
    "        pd_df.a,\n",
    "        pl_df.b,\n",
    "        greatest(pd_df.a, pl_df.b) as max_ab,\n",
    "        sum(greatest(pd_df.a, pl_df.b)) over(order by key) as cumsum_max_ab\n",
    "    from\n",
    "        pd_df join pl_df on pd_df.key = pl_df.key\n",
    "\"\"\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3db8d",
   "metadata": {},
   "source": [
    "## What is supported in SQL?\n",
    "\n",
    "### The polars team claim they are trying to have everything that PostgreSQL support, but it's still wip\n",
    "\n",
    "### What's supported right now\n",
    "\n",
    "- `SELECT`\n",
    "- `DISTINCT`\n",
    "- `FROM`\n",
    "- `JOIN (CROSS JOIN, FULL JOIN, INNER JOIN, [LEFT | RIGHT] [ANTI | SEMI] JOIN`, \n",
    "- `WHERE`\n",
    "- `GROUP BY`\n",
    "- `HAVING`\n",
    "- `ORDER BY`\n",
    "- `LIMIT/OFFSET`\n",
    "- `EXCEPT`\n",
    "- `INTERSECT`\n",
    "- `UNION [ALL]`\n",
    "- `UNNEST`\n",
    "- `WITH`\n",
    "- `OVER`\n",
    "- Lots and lots of functions...\n",
    "\n",
    "### Not supported\n",
    "\n",
    "- `QUALIFY`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b887751",
   "metadata": {},
   "source": [
    "## Not covered: SQLContext, other connectors, batch read, caching\n",
    "\n",
    "You can connect to CSVs, JSON files, Excel, AVRO, Feather, Parquet..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201126f3",
   "metadata": {},
   "source": [
    "## Working with BigQuery\n",
    "\n",
    "There is no direct connector to BigQuery, however, BigQuery queries can be transfered in Arrow format\n",
    "\n",
    "```python\n",
    "import polars as pl\n",
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Perform a query.\n",
    "QUERY = \"\"\"\n",
    "    SELECT a,b,c\n",
    "    FROM some_table \n",
    "    WHERE condition\n",
    "    LIMIT 100\"\"\"\"\n",
    "\n",
    "query_job = client.query(QUERY)  \n",
    "rows = query_job.result() \n",
    "\n",
    "df = pl.from_arrow(rows.to_arrow())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06522bd4",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "1. Used correctly, `polars` is superior to `pandas` in terms of performance<br>\n",
    "2. Not limited to RAM when using lazy execution<br>\n",
    "2. SQL api, Lazy execution are very handy<br>\n",
    "3. I personally prefer the functional expression API<br>\n",
    "4. Multiple connectors are availble (parquet, Excel, CSV, ...)<br>\n",
    "5. As of Dec 2024 numpy/pandas conversion happens behind the scenes when we fit models and plot stuff, so there is no speed up on scikit-learn/LightGBM/catboost/matplotlib - but, polars is moving quickly and we might see more and more direct integrations<br>\n",
    "6. Rust - since this is A rapidly growing community, it might have some future for DS/Analytics too, and then polars will be rust's pandas equivalent<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4ffa6c",
   "metadata": {},
   "source": [
    "## Bonus: `great-tables`\n",
    "\n",
    "Integrates seamlessly with `polars` you can also use the `selectors` directly when selecting columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8437d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_tables import GT, md, html, nanoplot_options\n",
    "from colorzero import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c37de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_file_location = './limited-memory-example/yellow_tripdata_2015-01.csv'\n",
    "df = pl.read_csv(_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ebe66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = (\n",
    "    df\n",
    "    .sort(pl.col('tpep_pickup_datetime'), descending=False)\n",
    "    .group_by_dynamic(pl.col('tpep_pickup_datetime').str.to_datetime('%Y-%m-%d %H:%M:%S'), every=\"1w\")\n",
    "    .agg(\n",
    "        pl.col('passenger_count').mean().alias('average_passenger_count'),\n",
    "        pl.col('trip_distance').mean().alias('average_trip_distance'),\n",
    "        pl.col('fare_amount').mean(),\n",
    "        pl.col('extra').mean(),\n",
    "        pl.col('mta_tax').mean(),\n",
    "        pl.col('tip_amount').mean(),\n",
    "        pl.col('tolls_amount').mean(),\n",
    "        pl.col('total_amount').mean())\n",
    "    ).rename(mapping={'tpep_pickup_datetime':'week'})\n",
    "\n",
    "bw2 = (\n",
    "    df\n",
    "    .sort(pl.col('tpep_pickup_datetime'), descending=False)\n",
    "    .group_by_dynamic(pl.col('tpep_pickup_datetime').str.to_datetime('%Y-%m-%d %H:%M:%S'), every=\"1d\")\n",
    "    .agg(pl.col('passenger_count').sum().alias('passenger_count_daily'))\n",
    "    .rename(mapping={'tpep_pickup_datetime':'day'})\n",
    "    .sort(pl.col('day'), descending=False)\n",
    "    .group_by_dynamic(pl.col('day'), every=\"1w\")\n",
    "    .agg(pl.col('passenger_count_daily').implode())\n",
    "    .with_columns(pl.col('passenger_count_daily').list.get(0))\n",
    "    .rename(mapping={'day':'week'})\n",
    "    )\n",
    "\n",
    "gt1 = (\n",
    "    bw.join(bw2, on='week', how='inner').style\n",
    "        .tab_header('NYC Taxi dataset', subtitle=f\"Weekly statistics between Dec 29, 2014 to Jan 26, 2015\")\n",
    "        .tab_stub(rowname_col='week')\n",
    "        .tab_source_note(source_note='Kaggle, July 2017. https://www.kaggle.com/competitions/nyc-taxi-trip-duration')\n",
    "        .tab_spanner(label='Averages', columns=['average_passenger_count', 'average_trip_distance'])\n",
    "        .tab_spanner(label='Avg. Costs', columns=['fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'total_amount'])\n",
    "        .fmt_currency(columns=['fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'total_amount'])\n",
    "        .fmt_date(columns=['week'], date_style='m_day_year')\n",
    "        .fmt_number(columns=['average_passenger_count', 'average_trip_distance'], compact=True)\n",
    "        .fmt_nanoplot(columns='passenger_count_daily', autoscale=True)\n",
    "        .cols_label(\n",
    "            average_passenger_count=html('Passenger<br>count'),\n",
    "            average_trip_distance=html('Trip<br>distance'),\n",
    "            fare_amount=html('Fare'),\n",
    "            extra='Extra',\n",
    "            mta_tax='MTA tax',\n",
    "            tip_amount='Tip',\n",
    "            tolls_amount=html('Tolls'),\n",
    "            total_amount=html('Total'),\n",
    "            passenger_count_daily=html('Passenger count<br>(daily)')\n",
    "        )\n",
    ")\n",
    "low_col = Color('lime') - Saturation(0.4)\n",
    "high_col = Color('yellow') - Saturation(0.2)\n",
    "gt2 = (\n",
    "    gt1\n",
    "    .data_color(\n",
    "        palette=[low_col.html, high_col.html], \n",
    "        columns=[k for k,v in bw.schema.items() \n",
    "                 if v.is_numeric() \n",
    "                 and k not in ('average_passenger_count', 'average_trip_distance')])\n",
    "    .data_color(\n",
    "        palette=[\"white\", \"blue\"], \n",
    "        columns=['average_passenger_count', 'average_trip_distance']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d2193",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d415dc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
